{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2571636,"sourceType":"datasetVersion","datasetId":1561333}],"dockerImageVersionId":30527,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Preprocessing del dataset xView per il problema di object detection\n\n## About this notebook\nQuesto notebook viene utilizzato per la preparazione del dataset. In particolare al termine di tutte le operazioni avremo una suddivisione dei dati in train-validation-test (labellati) + test (non labellato). Ci servirà per eseguire l'addestramento tramite reti YOLOv8 e ResNet.\nVengono estratte tutte le informazioni utili dal file xView_train.geojson e convertite in un formato adatto alle nostre reti (formato YOLO e COCO).\nDal momento che le nostre reti lavorano con dimensioni di input fissate, nel nostro caso 640x640, tutte le immagini, ad eccezione di quelle di test, vengono croppate per rispettare le dimensioni scelte. In questo modo la rete non esegue un resize automatico di conseguenza non rischiamo di perdere informazioni.\nDato che le immagini originali non sono tutte della stessa dimensione, potrebbe capitare che alcuni crop non ricadano nella dimensione scelta, per evitare questo problema abbiamo deciso anche di eseguire un padding sulle immagini di dimensione minore di 640x640.\nPer quanto riguarda invece le immagini di test (sia labellato che non labellato) non sono state croppate perchè in questo modo siamo capaci di capire il comportamento della rete sull'immagine a dimensioni originali sulla quale vogliamo fare detection. Sarà poi compito della rete dividere l'immagine in crop, fare predizione su questi ultimi e mettere insieme i risultati relativi ad una stessa immagine.\n\n### File structure\nLa cartella /kaggle/working conterrà il dataset che andrà in input alle reti per la detection (in altri 2 notebook).\nIn particolare avremo le seguenti directory:\n- images: contiene tutte le immagini di train, validation e test. Quelle appartenenti a train e validation sono croppate come indicato sopra. *Es img_0_640.jpg*\n- labels: per ogni immagine è presente un file di testo contenente tutti i relativi box. *Es img_0_640.txt*\n- YOLO_cfg: contiene 4 files: <b>*test.txt, train.txt, val.txt*</b> che contengono i percorsi alle immagini rispettivamente di test, train e validation. <b>*xView_yolo.yaml*</b> che è il file di configurazione preso in input dalla rete YOLO per far partire l'addestramento.\n- TestImages: contiene tutte le immagini di test (senza labels).\n\nE i seguenti files:\n- COCO_annotations.json: è la versione COCO del file di configurazione YOLO, che viene usato dalla rete ResNet.\n- xView_class_map.json: associa ad ogni classe (string) il corrispettivo indice (intero) da 0 a 59.\n- xview_labels.parquet: contiene tutti i box delle immagini in forma tabellata.","metadata":{"papermill":{"duration":0.015501,"end_time":"2023-08-20T09:37:09.975481","exception":false,"start_time":"2023-08-20T09:37:09.95998","status":"completed"},"tags":[]}},{"cell_type":"code","source":"shutil.rmtree('/kaggle/working/labels')\nshutil.rmtree('/kaggle/working/YOLO_cfg')\nshutil.rmtree('/kaggle/working/images')\nos.remove('/kaggle/working/xView_class_map.json')","metadata":{"execution":{"iopub.status.busy":"2023-12-30T12:02:43.024327Z","iopub.execute_input":"2023-12-30T12:02:43.024789Z","iopub.status.idle":"2023-12-30T12:02:44.243121Z","shell.execute_reply.started":"2023-12-30T12:02:43.024755Z","shell.execute_reply":"2023-12-30T12:02:44.240815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pathlib import Path\nimport pandas as pd\nimport cv2\nimport os\nimport numpy as np\nfrom os import sep\nimport shutil\nimport json\nimport yaml\nimport matplotlib.pyplot as plt\nimport random\nimport time\nfrom tqdm.notebook import tqdm_notebook\nimport concurrent.futures\nimport multiprocessing as mp\nfrom PIL import Image\nimport zipfile\nfrom IPython.display import FileLink","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.258781,"end_time":"2023-08-20T09:37:10.250093","exception":false,"start_time":"2023-08-20T09:37:09.991312","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-30T12:02:44.246908Z","iopub.execute_input":"2023-12-30T12:02:44.247460Z","iopub.status.idle":"2023-12-30T12:02:44.255831Z","shell.execute_reply.started":"2023-12-30T12:02:44.247426Z","shell.execute_reply":"2023-12-30T12:02:44.254712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Setup\nDefinizione di tutti i percorsi utili in questo notebook.","metadata":{"papermill":{"duration":0.015503,"end_time":"2023-08-20T09:37:10.281371","exception":false,"start_time":"2023-08-20T09:37:10.265868","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#Data sources\nDATA_FLDR_NM = 'Data'\nIN_DATASET_NM = 'xview-dataset'\nIMAGE_FLDR_NM = 'train_images'\nIN_LABELS_FLDR_NM = 'train_labels'\nLABELS_XML_NM = 'xView_train.geojson'\n\n#Output folders and file names\nOUT_DATASET_NM = 'xview-dataset-team1/xview-dataset-team1'\nCLASS_MAP_JSON_NM = 'xView_class_map.json'\nOUT_COCO_JSON_NM = 'COCO_annotations.json'\nOUT_IMAGE_FLDR_NM = 'images'\nOUT_LABELS_FLDR_NM = 'labels'\nOUT_CFG_FLDR_NM = 'YOLO_cfg'\nOUT_DATAFRAME_NM = 'xview_labels.parquet'\nYAML_NM = 'xview_yolo.yaml'\nCHUNK_WIDTH = 640  # width of the images being created\nCHUNK_HEIGHT = 640\nMIN_CHUNK_HEIGHT = 160 # no images will be kept if the image chunk is smaller than this\nMIN_CHUNK_WIDTH = 160\nIMAGE_WRITING = True #True to re-perform image cropping, False just to regenerated other data\nTEST_FRACTION = 0.1\nJPEG_COMPRESSION = 95 # For the saved files\nVAL_FRACTION = 0.1\nRANDOM_SEED = 2023\nDEBUG = False\n\n\nin_dataset_pth = Path('/kaggle/input/xview-dataset')\nout_dataset_pth = Path('/kaggle/working/')\nfuture_ds_img_fldr = Path(f'/kaggle/input/{OUT_DATASET_NM}/{OUT_IMAGE_FLDR_NM}') #Questo path serve per scrivere nei file .txt il percorso corretto alle immagini del dataset che esportiamo\nfuture_ds_cfg_fldr = Path(f'/kaggle/input/{OUT_DATASET_NM}/{OUT_CFG_FLDR_NM}')\n\n\nlabels_json_pth = in_dataset_pth / IN_LABELS_FLDR_NM / LABELS_XML_NM\nimg_fldr_pth = in_dataset_pth / IMAGE_FLDR_NM / IMAGE_FLDR_NM\nsave_images_fldr_pth = out_dataset_pth / OUT_IMAGE_FLDR_NM \nsave_labels_fldr_pth = out_dataset_pth / OUT_LABELS_FLDR_NM\nout_data_parquet_pth = out_dataset_pth / OUT_DATAFRAME_NM\nout_json_map_pth = out_dataset_pth / CLASS_MAP_JSON_NM \nclass_map_pth = out_dataset_pth / CLASS_MAP_JSON_NM\ncfg_fldr_pth = out_dataset_pth / OUT_CFG_FLDR_NM\ncoco_json_pth = out_dataset_pth / OUT_COCO_JSON_NM\nyolo_yaml_pth = cfg_fldr_pth / YAML_NM\ntrain_txt_pth = cfg_fldr_pth / 'train.txt'\nval_txt_pth = cfg_fldr_pth / 'train.txt'\ntest_txt_pth = cfg_fldr_pth / 'test.txt'\n\n\ndef make_empty_dir(directory):\n    if directory.is_dir():\n        shutil.rmtree(directory)\n    os.makedirs(directory)\n\nmake_empty_dir(cfg_fldr_pth)\nif IMAGE_WRITING:\n    make_empty_dir(save_images_fldr_pth)\n    make_empty_dir(save_labels_fldr_pth)\n\nrandom.seed(RANDOM_SEED)\n\nprint(f'The input images are found at {cfg_fldr_pth}')\nprint(f'The input labels are found at  {labels_json_pth}')\nprint(f'Configuration files will be saved to {cfg_fldr_pth}')\nprint(f'YOLO image files will be saved to {save_images_fldr_pth}')\nprint(f'YOLO labels files will be saved to {save_labels_fldr_pth}')","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.034866,"end_time":"2023-08-20T09:37:10.331386","exception":false,"start_time":"2023-08-20T09:37:10.29652","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-30T12:02:44.257274Z","iopub.execute_input":"2023-12-30T12:02:44.257683Z","iopub.status.idle":"2023-12-30T12:02:44.273155Z","shell.execute_reply.started":"2023-12-30T12:02:44.257646Z","shell.execute_reply":"2023-12-30T12:02:44.272028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Helper Functions","metadata":{"papermill":{"duration":0.0148,"end_time":"2023-08-20T09:37:10.361381","exception":false,"start_time":"2023-08-20T09:37:10.346581","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def convert_tif_to_jpg(input_path, output_path):\n    # Open the .tif image\n    with Image.open(input_path) as img:\n        # Save the image in .png format\n        img.save(output_path, format='JPEG')\n\n        \n#Questa funzione mi ritorna un dizionario contenente i box appartenenti a ciascun immagine (eventualmente si può limitare il numero di classi da considerare, grazie a class_lst)\ndef get_boxes(in_df, class_lst=[]):\n    if class_lst:\n        in_df = in_df[in_df['TYPE_ID'].isin(class_lst)]\n    unique_images = in_df.IMAGE_ID.unique().tolist() #serve per scorrere le immagini presenti nel df\n    boxs = {}\n\n    for image in tqdm_notebook(unique_images):\n        mask = in_df['IMAGE_ID'] == image #crea una maschera con valori 1 nelle locazioni in cui i box appartengono all'immagine corrente (image).\n        masked = in_df[mask][['TYPE_ID', 'XMIN', 'YMIN', 'XMAX', 'YMAX']] #accedo alle righe del df corrispondenti agli 1 della maschera.\n        boxs[image] = masked.values.tolist()\n    return boxs\n\n\ndef load_bgr_image(file_pth):\n    image_obj = cv2.imread(file_pth)\n    return image_obj\n\n\n#Adatta la lista di box in ingresso ai bordi dell'immagine definiti in chunk limits e converte le coordinate in formato yolo.\ndef match_boxes(box_list, chnk_lims):\n    boxes_lists = []\n    le, to = chnk_lims[0], chnk_lims[1]  # chunk_limits = [c, r, chunk_w, chunk_h]\n    w, h  = chnk_lims[2], chnk_lims[3]\n    for box in box_list:\n        o_left, o_top, o_right, o_bottom = box[1], box[2], box[3], box[4]\n        left, right = (o_left - le)/w, (o_right - le)/w  # translate and normalise\n        top, bottom = (o_top - to)/h, (o_bottom - to)/h\n\n        h_match = (0 <= left < 1) or (0 < right <= 1)\n        v_match = (0 <= top < 1) or (0 < bottom <= 1)\n\n        if v_match and h_match:\n            clipped = np.clip([left, top, right, bottom], a_min=0, a_max=1) #Dato che v_match e h_match possono entrambe essere verificate se anche solo uno tra (left, right) e (top, bottom) sono comprese tra 0 e 1\n                                                                            #quindi nel caso in cui 0<left<1 == true e 0<right<1 == false, dobbiamo mettere right a 1 in modo tale che il box non esca dal crop.\n            l, t, r, b = clipped[0], clipped[1], clipped[2], clipped[3]\n            bounding_box = [str(box[0]),\n                            str(round((l + r)/2, 5)),\n                            str(round((t + b)/2, 5)),\n                            str(round(r-l, 5)),\n                            str(round(b-t, 5))]\n            boxes_lists.append(bounding_box)\n    return boxes_lists\n\n\ndef zip_dir(directory = os.curdir, file_name = 'directory.zip'):\n    os.chdir(directory)\n    zip_ref = zipfile.ZipFile(file_name, mode='w')\n    for folder, _, files in os.walk(directory):\n        for file in files:\n            if file_name in file:\n                pass\n            else:\n                zip_ref.write(os.path.join(folder, file))\n\n    return FileLink(file_name)","metadata":{"papermill":{"duration":0.05672,"end_time":"2023-08-20T09:37:10.463018","exception":false,"start_time":"2023-08-20T09:37:10.406298","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-30T12:02:44.275576Z","iopub.execute_input":"2023-12-30T12:02:44.276111Z","iopub.status.idle":"2023-12-30T12:02:44.290323Z","shell.execute_reply.started":"2023-12-30T12:02:44.276082Z","shell.execute_reply":"2023-12-30T12:02:44.289238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Extraction and Cleaning","metadata":{}},{"cell_type":"markdown","source":"Estrazione delle sole colonne di interesse.","metadata":{}},{"cell_type":"code","source":"with open(labels_json_pth, 'r') as infile:\n    data = json.load(infile)\n    keys = list(data.keys())\n\nfeature_list = data['features']\nCOLUMNS = ['IMAGE_ID', 'TYPE_ID', 'XMIN', 'YMIN', 'XMAX', 'YMAX']\n\ndata = []\nfor feature in tqdm_notebook(feature_list):\n    properties = feature['properties'] # a dict\n    img_id = properties['image_id']  # '389.tif'\n    type_id = properties['type_id']\n    bbox = properties['bounds_imcoords'].split(\",\")  # eg '1917,38,1958,64'\n    one_row = [img_id, type_id, bbox[0], bbox[1], bbox[2], bbox[3]]\n    data.append(one_row)\n\ninstances = len(data)\nprint(f'There are {instances} object instances in the original dataset')","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":21.245452,"end_time":"2023-08-20T09:37:31.724333","exception":false,"start_time":"2023-08-20T09:37:10.478881","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-30T12:02:44.292015Z","iopub.execute_input":"2023-12-30T12:02:44.292353Z","iopub.status.idle":"2023-12-30T12:03:06.580126Z","shell.execute_reply.started":"2023-12-30T12:02:44.292324Z","shell.execute_reply":"2023-12-30T12:03:06.579045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Conversione delle colonne contenenti numeri in interi.","metadata":{"papermill":{"duration":0.015391,"end_time":"2023-08-20T09:37:31.755149","exception":false,"start_time":"2023-08-20T09:37:31.739758","status":"completed"},"tags":[]}},{"cell_type":"code","source":"df = pd.DataFrame(data, columns = COLUMNS)\ndf[['XMIN', 'YMIN', 'XMAX', 'YMAX']] = df[['XMIN', 'YMIN', 'XMAX', 'YMAX']].apply(pd.to_numeric)\ndf.head()","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":3.979887,"end_time":"2023-08-20T09:37:35.750799","exception":false,"start_time":"2023-08-20T09:37:31.770912","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-30T12:03:06.581506Z","iopub.execute_input":"2023-12-30T12:03:06.581830Z","iopub.status.idle":"2023-12-30T12:03:09.145845Z","shell.execute_reply.started":"2023-12-30T12:03:06.581802Z","shell.execute_reply":"2023-12-30T12:03:09.144766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Rimozione di annotazioni errate.","metadata":{"papermill":{"duration":0.015796,"end_time":"2023-08-20T09:37:35.782811","exception":false,"start_time":"2023-08-20T09:37:35.767015","status":"completed"},"tags":[]}},{"cell_type":"code","source":"df = df[(df.TYPE_ID != 75) & (df.TYPE_ID != 82)]   # removing erroneous labels\nprint(f'{instances - len(df)} rows removed, leaving {len(df)} rows')","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.090876,"end_time":"2023-08-20T09:37:35.889334","exception":false,"start_time":"2023-08-20T09:37:35.798458","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-30T12:03:09.147245Z","iopub.execute_input":"2023-12-30T12:03:09.147556Z","iopub.status.idle":"2023-12-30T12:03:09.233002Z","shell.execute_reply.started":"2023-12-30T12:03:09.147529Z","shell.execute_reply":"2023-12-30T12:03:09.231730Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.033242,"end_time":"2023-08-20T09:37:35.938148","exception":false,"start_time":"2023-08-20T09:37:35.904906","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-30T12:03:09.234432Z","iopub.execute_input":"2023-12-30T12:03:09.234860Z","iopub.status.idle":"2023-12-30T12:03:09.247817Z","shell.execute_reply.started":"2023-12-30T12:03:09.234820Z","shell.execute_reply":"2023-12-30T12:03:09.246599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Rimozione dell'immagine 1395 che non esiste nel dataset","metadata":{"papermill":{"duration":0.015627,"end_time":"2023-08-20T09:37:35.969758","exception":false,"start_time":"2023-08-20T09:37:35.954131","status":"completed"},"tags":[]}},{"cell_type":"code","source":"old_length = len(df)\ndf = df[df.IMAGE_ID != '1395.tif']\nprint(f'{old_length - len(df)} rows removed, leaving {len(df)}')\ndf.head()","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.206868,"end_time":"2023-08-20T09:37:36.192499","exception":false,"start_time":"2023-08-20T09:37:35.985631","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-30T12:03:09.249643Z","iopub.execute_input":"2023-12-30T12:03:09.249970Z","iopub.status.idle":"2023-12-30T12:03:09.394446Z","shell.execute_reply.started":"2023-12-30T12:03:09.249943Z","shell.execute_reply":"2023-12-30T12:03:09.393298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Rimozione di tutti i box che hanno area nulla. (perchè hanno almeno una dimensione nulla)","metadata":{}},{"cell_type":"code","source":"old_length = len(df)\ndf = df[df.XMIN != df.XMAX]\ndf = df[df.YMIN != df.YMAX]\nprint(f'{old_length - len(df)} rows removed, leaving {len(df)}')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-30T12:03:09.399040Z","iopub.execute_input":"2023-12-30T12:03:09.399383Z","iopub.status.idle":"2023-12-30T12:03:09.543884Z","shell.execute_reply.started":"2023-12-30T12:03:09.399355Z","shell.execute_reply":"2023-12-30T12:03:09.542456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Vengono mappate le classi su un insieme ordinato di indici che va da 0 a 59.","metadata":{"papermill":{"duration":0.017306,"end_time":"2023-08-20T09:37:36.22665","exception":false,"start_time":"2023-08-20T09:37:36.209344","status":"completed"},"tags":[]}},{"cell_type":"code","source":"old_dict = {\n    11:'Fixed-wing Aircraft', 12:'Small Aircraft', 13:'Passenger/Cargo Plane', 15:'Helicopter',\n    17:'Passenger Vehicle', 18:'Small Car', 19:'Bus', 20:'Pickup Truck', 21:'Utility Truck',\n    23:'Truck', 24:'Cargo Truck', 25:'Truck Tractor w/ Box Trailer', 26:'Truck Tractor',27:'Trailer',\n    28:'Truck Tractor w/ Flatbed Trailer', 29:'Truck Tractor w/ Liquid Tank', 32:'Crane Truck',\n    33:'Railway Vehicle', 34:'Passenger Car', 35:'Cargo/Container Car', 36:'Flat Car', 37:'Tank car',\n    38:'Locomotive', 40:'Maritime Vessel', 41:'Motorboat', 42:'Sailboat', 44:'Tugboat', 45:'Barge',\n    47:'Fishing Vessel', 49:'Ferry', 50:'Yacht', 51:'Container Ship', 52:'Oil Tanker',\n    53:'Engineering Vehicle', 54:'Tower crane', 55:'Container Crane', 56:'Reach Stacker',\n    57:'Straddle Carrier', 59:'Mobile Crane', 60:'Dump Truck', 61:'Haul Truck', 62:'Scraper/Tractor',\n    63:'Front loader/Bulldozer', 64:'Excavator', 65:'Cement Mixer', 66:'Ground Grader', 71:'Hut/Tent',\n    72:'Shed', 73:'Building', 74:'Aircraft Hangar', 76:'Damaged Building', 77:'Facility', 79:'Construction Site',\n    83:'Vehicle Lot', 84:'Helipad', 86:'Storage Tank', 89:'Shipping container lot', 91:'Shipping Container',\n    93:'Pylon', 94:'Tower'}\n\n\nold_keys = sorted(list(old_dict.keys()))\nnew_dict = {old_dict[x]:y for y, x in enumerate(old_keys)}\nclass_map_dict = {y:old_dict[x] for y, x in enumerate(old_keys)}\nwith open(out_json_map_pth, \"w\") as json_file:\n    json.dump(class_map_dict, json_file)\nprint(class_map_dict)\n\ndf['TYPE_ID'] = df['TYPE_ID'].apply(lambda x: new_dict[old_dict[x]])\ndf.head(3)","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.032082,"end_time":"2023-08-20T09:37:36.275789","exception":false,"start_time":"2023-08-20T09:37:36.243707","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-30T12:03:09.546368Z","iopub.execute_input":"2023-12-30T12:03:09.546799Z","iopub.status.idle":"2023-12-30T12:03:09.846120Z","shell.execute_reply.started":"2023-12-30T12:03:09.546759Z","shell.execute_reply":"2023-12-30T12:03:09.845041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Main Process\n- Split in train-test-validation.\n- Divisione delle immagini in crop.\n- Salvataggio dei crop in formato jpg nella cartella /kaggle/working/images.\n- Conversione delle labels in formato YOLO: x_center, y_center, width, height (tutte normalizzate).","metadata":{"papermill":{"duration":0.023998,"end_time":"2023-08-20T09:38:27.136997","exception":false,"start_time":"2023-08-20T09:38:27.112999","status":"completed"},"tags":[]}},{"cell_type":"code","source":"boxes_dict = get_boxes(df) #restituisce un dizionario in forma {filename:[['TYPE_ID', 'XMIN', 'YMIN', 'XMAX', 'YMAX'],[..],[..],..]}","metadata":{"execution":{"iopub.status.busy":"2023-12-30T12:03:09.847454Z","iopub.execute_input":"2023-12-30T12:03:09.847782Z","iopub.status.idle":"2023-12-30T12:04:26.740888Z","shell.execute_reply.started":"2023-12-30T12:03:09.847755Z","shell.execute_reply":"2023-12-30T12:04:26.739567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process_image(img_fn, \n                  dir_pth=img_fldr_pth, \n                  boxes=boxes_dict, \n                  out_dir=save_images_fldr_pth, \n                  c_height=CHUNK_HEIGHT, \n                  c_width=CHUNK_WIDTH,  \n                  jpg_q=JPEG_COMPRESSION,\n                  min_h=MIN_CHUNK_HEIGHT,\n                  min_w=MIN_CHUNK_WIDTH,\n                  writing=IMAGE_WRITING\n                 ):\n    \n    labels_list = boxes[img_fn]\n    img_pth = str(dir_pth / img_fn)\n    im = load_bgr_image(img_pth)\n    full_h, full_w, _ = im.shape\n    y_boxes= {}\n    f_names, widths, heights = [], [], []\n    \n    for r in range(0, full_h, c_height):\n        for c in range(0, full_w, c_width):\n            stem = img_fn.split('.')[0]\n            fn = str(f\"img_{stem}_{r}_{c}.jpg\")\n            out_pth = str(out_dir / fn)\n            width = c_width\n            height = c_height\n            if r + height > full_h:\n                height = full_h - r\n            if c + width > full_w:\n                width = full_w - c\n            big_enough = (height > min_h) and (width > min_w) #non consideriamo i crop con dimensione inferiore a min_h x min_w (160x160)\n            if big_enough:\n                if (height == 640) and (width == 640):  \n                    if writing:\n                        cv2.imwrite(out_pth, im[r:r+height, c:c+width,:],  [int(cv2.IMWRITE_JPEG_QUALITY), jpg_q])\n                        \n                else:        #Facciamo padding all'immagine per avere tutti i crop di dimensione 640x640\n                    temp = im[r:r+height, c:c+width, :]\n                    if width < 640:\n                        padding = np.zeros((height, 640-width, 3), dtype=np.uint8)\n                        temp = np.concatenate((temp,padding), axis=1)     #concatena l'immagine temp e gli zeri lungo la direzione orizzontale\n                        width = 640\n                        \n                    if height < 640:\n                        padding = np.zeros((640-height, width, 3), dtype=np.uint8)\n                        temp = np.concatenate((temp,padding), axis=0)     #concatena l'immagine temp e gli zeri lungo la direzione verticale\n                        height = 640\n                        \n                    if writing:\n                        cv2.imwrite(out_pth, temp,  [int(cv2.IMWRITE_JPEG_QUALITY), jpg_q])\n                \n                    if(temp.shape != (640,640,3)):\n                        print('errore')\n                    \n                    \n                chunk_limits = [c, r, width, height]\n                y_boxes[fn] = match_boxes(labels_list, chunk_limits) #match boxes normalizza le coordinate dei box e le trasforma in [id, centrox, centroy, width, height]\n                f_names.append(fn) #lista contenente i nomi di tutti i crop dell'immagine\n                widths.append(width) #lista contenente le larghezze di tutti i crop dell'immagine\n                heights.append(height) #lista contenente le altezze di tutti i crop dell'immagine\n    return f_names, widths, heights, y_boxes","metadata":{"execution":{"iopub.status.busy":"2023-12-30T12:04:26.742959Z","iopub.execute_input":"2023-12-30T12:04:26.743418Z","iopub.status.idle":"2023-12-30T12:04:26.810041Z","shell.execute_reply.started":"2023-12-30T12:04:26.743377Z","shell.execute_reply":"2023-12-30T12:04:26.808868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_fns = df.IMAGE_ID.unique().tolist() #ci prendiamo la lista di tutte le immagini (senza ripetizioni)","metadata":{"execution":{"iopub.status.busy":"2023-12-30T12:04:26.811682Z","iopub.execute_input":"2023-12-30T12:04:26.812065Z","iopub.status.idle":"2023-12-30T12:04:26.960386Z","shell.execute_reply.started":"2023-12-30T12:04:26.812027Z","shell.execute_reply":"2023-12-30T12:04:26.959230Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filenames = [x for x in os.listdir('/kaggle/input/xview-dataset/train_images/train_images') if x.endswith(\".tif\")]\n\ntotal_images = len(filenames)\nindices = list(range(total_images))\nrandom.shuffle(indices)\n\ntrain_fraction = 1 - TEST_FRACTION - VAL_FRACTION\ntrain_sp = int(np.floor(train_fraction * len(indices))) #training-validation split\nvalid_sp = int(np.floor(VAL_FRACTION * len(indices))) + train_sp #validation-test split\ntrain_idx, val_idx, test_idx = indices[:train_sp], indices[train_sp:valid_sp], indices[valid_sp:]\n\nprint(' Training set size: \\t', len(train_idx))\nprint(' Validation set size: \\t', len(val_idx))\nprint(' Test set size: \\t', len(test_idx))\nprint(' Total dataset: \\t', total_images)","metadata":{"execution":{"iopub.status.busy":"2023-12-30T12:04:26.962397Z","iopub.execute_input":"2023-12-30T12:04:26.962813Z","iopub.status.idle":"2023-12-30T12:04:26.980077Z","shell.execute_reply.started":"2023-12-30T12:04:26.962776Z","shell.execute_reply":"2023-12-30T12:04:26.978991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"files = ['train.txt', 'val.txt', 'test.txt']\nsplits = [train_idx, val_idx, test_idx]\n\nfor fn, split in zip(files, splits):\n    txt_pth = cfg_fldr_pth / fn\n    with open(txt_pth, 'a') as f:\n        for ind in split:\n            f.write(str(future_ds_img_fldr / filenames[ind]) + '\\n')\n        print(f'{fn[:-4]} file written to {txt_pth}, with {len(split) } samples')","metadata":{"execution":{"iopub.status.busy":"2023-12-30T12:04:26.981448Z","iopub.execute_input":"2023-12-30T12:04:26.981760Z","iopub.status.idle":"2023-12-30T12:04:26.997167Z","shell.execute_reply.started":"2023-12-30T12:04:26.981731Z","shell.execute_reply":"2023-12-30T12:04:26.996002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Separazione delle immagini di train e validation da quelle di test in quanto solamente sulle prime vogliamo eseguire i crop.","metadata":{}},{"cell_type":"code","source":"dataframe = df\nprint(len(df))\n      \nwith open('/kaggle/working/YOLO_cfg/test.txt', 'r') as file:\n    lines = [line.strip().split('/')[-1] for line in file.readlines()]\n\ndf2 = df[df['IMAGE_ID'].isin(lines)] #df2 contiene tutti i box delle sole immagini di test (presenti in test.txt)\ndf = df[~df['IMAGE_ID'].isin(lines)] #df contiene tutti i box delle immagini di train + validation\n\nprint(len(df))\n\nimg_fns = df.IMAGE_ID.unique().tolist() #img fns contiene tutti i box delle immagini di train + validation\nimg_fns2 = df2.IMAGE_ID.unique().tolist() #img fns2 contiene tutti i box delle immagini di test (locale)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-30T12:04:26.998592Z","iopub.execute_input":"2023-12-30T12:04:26.998885Z","iopub.status.idle":"2023-12-30T12:04:27.365147Z","shell.execute_reply.started":"2023-12-30T12:04:26.998859Z","shell.execute_reply":"2023-12-30T12:04:27.363963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Verifica che le immagini di test siano state correttamente separate da quelle di train e val.","metadata":{}},{"cell_type":"code","source":"print(len(img_fns))\nprint(len(img_fns2))","metadata":{"execution":{"iopub.status.busy":"2023-12-30T12:04:27.366724Z","iopub.execute_input":"2023-12-30T12:04:27.367398Z","iopub.status.idle":"2023-12-30T12:04:27.372833Z","shell.execute_reply.started":"2023-12-30T12:04:27.367362Z","shell.execute_reply":"2023-12-30T12:04:27.371663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Esecuzione della funzione process_image che realizza i crop.","metadata":{}},{"cell_type":"code","source":"start_time = time.time()\nnum_threads = mp.cpu_count() \noverall_progress = tqdm_notebook(total=len(img_fns), desc=\"Creating and saving image tiles\")\nyolo_boxes= {}\nfile_names, widths, heights = [], [], []\n\nwith concurrent.futures.ThreadPoolExecutor(max_workers=num_threads) as executor:\n    for f_names, c_widths, c_heights, y_boxes in executor.map(process_image, img_fns): #qui eseguiamo i crop per tutte le immagini di train + val\n        file_names.extend(f_names)\n        widths.extend(c_widths)\n        heights.extend(c_heights)\n        yolo_boxes.update(y_boxes)\n        overall_progress.update(1)\noverall_progress.close()\n\nimage_data = {file_names[i]: [widths[i], heights[i]] for i in range(len(file_names))}\ntime_taken=time.time() - start_time","metadata":{"execution":{"iopub.status.busy":"2023-12-30T12:04:27.374351Z","iopub.execute_input":"2023-12-30T12:04:27.375165Z","iopub.status.idle":"2023-12-30T12:07:23.715614Z","shell.execute_reply.started":"2023-12-30T12:04:27.375126Z","shell.execute_reply":"2023-12-30T12:07:23.714684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Conversione e copia delle immagini indicate in test.txt dal dataset di input alla cartella /kaggle/working/images","metadata":{}},{"cell_type":"code","source":"print(len(os.listdir('/kaggle/working/images')))\n\nwith open('/kaggle/working/YOLO_cfg/test.txt') as file:\n    lines = [line.strip() for line in file] #ottengo il percorso dell'immagine\n\nfor line in lines:\n    img_name = line.split('/')[-1]\n    img_name_jpg = 'img_' + img_name.split('.')[0] + '.jpg'\n    convert_tif_to_jpg('/kaggle/input/xview-dataset/train_images/train_images/' + img_name, '/kaggle/working/images/' + img_name_jpg)\n\nprint(len(os.listdir('/kaggle/working/images')))    ","metadata":{"execution":{"iopub.status.busy":"2023-12-30T12:07:23.716769Z","iopub.execute_input":"2023-12-30T12:07:23.717650Z","iopub.status.idle":"2023-12-30T12:08:08.208787Z","shell.execute_reply.started":"2023-12-30T12:07:23.717618Z","shell.execute_reply":"2023-12-30T12:08:08.207660Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Per tutte le immagini contenute in lines (righe di test.txt) convertiamo le labels al formato YOLO","metadata":{}},{"cell_type":"code","source":"print(len(yolo_boxes))\nfor line in lines:\n    img_name_tif = line.strip().split('/')[-1]\n    img_name_jpg = 'img_' + img_name_tif.split('.')[0] + '.jpg'\n    img = plt.imread('/kaggle/working/images/' + img_name_jpg)\n    \n    height, width, _ = img.shape\n   \n    chunk_limits = [0,0,width, height]\n    label_list = boxes_dict[img_name_tif]\n    \n    yolo_boxes[img_name_jpg] = match_boxes(label_list, chunk_limits)\n    file_names.append(img_name_jpg)\n    widths.append(width)\n    heights.append(height)\nprint(len(yolo_boxes))","metadata":{"execution":{"iopub.status.busy":"2023-12-30T12:08:08.210032Z","iopub.execute_input":"2023-12-30T12:08:08.210395Z","iopub.status.idle":"2023-12-30T12:08:17.613323Z","shell.execute_reply.started":"2023-12-30T12:08:08.210366Z","shell.execute_reply":"2023-12-30T12:08:17.611993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A partire da yolo_boxes, dizionario che contiene i box di tutte le immagini, creo un file di testo per ogni immagine contenente le labels nel formato [id, centro_x, centro_y, width, height]","metadata":{}},{"cell_type":"code","source":"cont = 0\nall_image_files = os.listdir(save_images_fldr_pth)\nfor image_fn in tqdm_notebook(all_image_files):\n    stem = image_fn.split('.')[0]\n    fn = str (stem) + '.txt'\n    txt_pth = str(save_labels_fldr_pth / fn)\n    seperator = ' '\n    with open(txt_pth, 'a') as f:\n        if image_fn in yolo_boxes:\n            cont += 1\n            for bbox in yolo_boxes[image_fn]:\n                txt = seperator.join(bbox) + '\\n'\n                f.write(txt)","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.061168,"end_time":"2023-08-20T09:38:33.148538","exception":false,"start_time":"2023-08-20T09:38:33.08737","status":"completed"},"pycharm":{"is_executing":true},"tags":[],"execution":{"iopub.status.busy":"2023-12-30T12:08:17.616266Z","iopub.execute_input":"2023-12-30T12:08:17.616607Z","iopub.status.idle":"2023-12-30T12:08:19.358343Z","shell.execute_reply.started":"2023-12-30T12:08:17.616578Z","shell.execute_reply":"2023-12-30T12:08:19.357090Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Creazione di un dataframe contenente tutti i box. Utile successivamente.","metadata":{}},{"cell_type":"code","source":"text_paths = [save_labels_fldr_pth / x for x in os.listdir(save_labels_fldr_pth) if x.endswith(\".txt\")]\ncolumn_names = ['Class_ID', 'x_center', 'y_center', 'width', 'height']\ndata = []\nfor file_path in text_paths:\n    with open(file_path, 'r') as file:\n        for line in file:\n            values = line.strip().split(' ')\n            row_data = {col: val for col, val in zip(column_names, values)}\n            row_data['File_Name'] = file_path.name\n            data.append(row_data)\n\nout_data = pd.DataFrame(data)\nout_data['Class_ID']=out_df['Class_ID'].astype(int)\nout_data['Class_Name'] = out_df['Class_ID'].map(class_map_dict).fillna('unknown')\nout_data = out_df[['File_Name', 'Class_Name', 'Class_ID', 'x_center', 'y_center', 'width', 'height']]\n\nout_data.head()\n","metadata":{"papermill":{"duration":0.460441,"end_time":"2023-08-20T09:38:33.635774","exception":false,"start_time":"2023-08-20T09:38:33.175333","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-30T12:08:19.359810Z","iopub.execute_input":"2023-12-30T12:08:19.360128Z","iopub.status.idle":"2023-12-30T12:08:22.838681Z","shell.execute_reply.started":"2023-12-30T12:08:19.360095Z","shell.execute_reply":"2023-12-30T12:08:22.837564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creazione del file in formato YOLO","metadata":{}},{"cell_type":"code","source":"config = {'train': str(future_ds_cfg_fldr / files[0]),\n          'val': str(future_ds_cfg_fldr / files[1]),\n          'test': str(future_ds_cfg_fldr / files[2]),\n          'nc': len(class_map_dict),\n          'names': class_map_dict\n          }\n\nwith open(yolo_yaml_pth, \"w\") as file:\n    yaml.dump(config, file, default_style=None, default_flow_style=False, sort_keys=False)\nprint(f'yaml file written to {yolo_yaml_pth}')","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.074085,"end_time":"2023-08-20T09:38:36.561513","exception":false,"start_time":"2023-08-20T09:38:36.487428","status":"completed"},"pycharm":{"is_executing":true},"tags":[],"execution":{"iopub.status.busy":"2023-12-30T12:08:22.840092Z","iopub.execute_input":"2023-12-30T12:08:22.840427Z","iopub.status.idle":"2023-12-30T12:08:22.854680Z","shell.execute_reply.started":"2023-12-30T12:08:22.840399Z","shell.execute_reply":"2023-12-30T12:08:22.853348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## YOLO to COCO\nConversione del file dal formato YOLO al formato COCO\n\nimages:  \n`{\"id\": int, \"width\": int, \"height\": int, \"file_name\": str, }`   \nannotations:  \n`{\"id\": int, \"image_id\": int, \"category_id\": int, \"area\": float, \"bbox\": [x,y,width,height]}`  \ncategories:  \n`[{\"id\": int, \"name\": str}]`","metadata":{}},{"cell_type":"markdown","source":"Estrazione delle informazioni necessarie per la sezione \"images\" del file COCO.","metadata":{}},{"cell_type":"code","source":"image_data = {'width': widths, 'height' : heights, 'file_name':file_names}\nim_df = pd.DataFrame(image_data)\nim_df['id'] = im_df['file_name'].str.replace(r'\\D', '', regex=True).astype(int)\nim_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-30T12:08:22.856717Z","iopub.execute_input":"2023-12-30T12:08:22.857160Z","iopub.status.idle":"2023-12-30T12:08:22.939364Z","shell.execute_reply.started":"2023-12-30T12:08:22.857126Z","shell.execute_reply":"2023-12-30T12:08:22.938505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def row_to_dict(row):\n    return {\n        'id': row['id'],\n        'width': row['width'],\n        'height':row['height'],\n        'file_name':row['file_name']\n    }\n\nim_list = im_df.apply(lambda row: row_to_dict(row), axis=1).tolist()\n[print(val) for val in im_list[:4]]","metadata":{"execution":{"iopub.status.busy":"2023-12-30T12:08:22.940853Z","iopub.execute_input":"2023-12-30T12:08:22.942522Z","iopub.status.idle":"2023-12-30T12:08:23.307988Z","shell.execute_reply.started":"2023-12-30T12:08:22.942480Z","shell.execute_reply":"2023-12-30T12:08:23.306984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Estrazione e conversione delle informazioni per la sezione \"annotations\" del file COCO.","metadata":{}},{"cell_type":"code","source":"annotations_df = out_data.copy()\nannotations_df['image_id'] = annotations_df['File_Name'].str.replace(r'\\D', '', regex=True).astype(int)\nannotations_df= annotations_df.rename(columns={'height': 'h', 'width': 'w'})\nan_df = annotations_df.merge(im_df, left_on='image_id', right_on='id', how='left')\nan_df['x_center']= (an_df['x_center'].astype(np.float64)*an_df['width']).round(decimals=0)\nan_df['y_center']= (an_df['y_center'].astype(np.float64)*an_df['height']).round(decimals=0)\nan_df['w']= (an_df['w'].astype(np.float64)*an_df['width']).round(decimals=0)\nan_df['h']= (an_df['h'].astype(np.float64)*an_df['height']).round(decimals=0)\nan_df['Class_ID']= an_df['Class_ID'].astype(int)\nan_df = an_df.drop(columns=['File_Name', 'file_name', 'width', 'height', 'id'])\nan_df['left'] = (an_df['x_center'] - an_df['w']/2).round(decimals=0)\nan_df['top'] =  (an_df['y_center'] - an_df['h']/2).round(decimals=0)\nan_df['bbox'] = ('[' + an_df['left'].astype(str) + ', ' \n              + an_df['top'].astype(str) + ', ' \n              + an_df['w'].astype(str) + ', '\n              + an_df['h'].astype(str) + ']')\nan_df['area'] = an_df['w'] * an_df['h']\nan_df = an_df.drop(columns=['x_center', 'y_center', 'w', 'h', 'left', 'top', 'Class_Name'])\nan_df.reset_index(inplace=True)\nan_df.rename(columns={'index': 'id'}, inplace=True)\nan_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-30T12:08:23.309287Z","iopub.execute_input":"2023-12-30T12:08:23.310125Z","iopub.status.idle":"2023-12-30T12:08:27.615730Z","shell.execute_reply.started":"2023-12-30T12:08:23.310097Z","shell.execute_reply":"2023-12-30T12:08:27.614662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def row_to_dict(row):\n    return {\n        'id': row['id'],\n        'image_id' : row['image_id'],\n        'category_id': row['Class_ID'],\n        'area':row['area'],\n        'bbox':row['bbox']\n    }\n\nan_list = an_df.apply(lambda row: row_to_dict(row), axis=1).tolist()\nprint(an_list[:4])\n","metadata":{"execution":{"iopub.status.busy":"2023-12-30T12:08:27.620783Z","iopub.execute_input":"2023-12-30T12:08:27.621202Z","iopub.status.idle":"2023-12-30T12:08:41.198230Z","shell.execute_reply.started":"2023-12-30T12:08:27.621172Z","shell.execute_reply":"2023-12-30T12:08:41.196989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Estrazione delle informazioni per la sezione \"categories\" del file COCO.","metadata":{}},{"cell_type":"code","source":"cat_list = [{\"id\": int(key), \"name\": val} for key, val in class_map_dict.items()]\nprint(cat_list[:4])","metadata":{"execution":{"iopub.status.busy":"2023-12-30T12:08:41.199660Z","iopub.execute_input":"2023-12-30T12:08:41.199978Z","iopub.status.idle":"2023-12-30T12:08:41.206195Z","shell.execute_reply.started":"2023-12-30T12:08:41.199952Z","shell.execute_reply":"2023-12-30T12:08:41.205226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Creazione e salvataggio del file COCO_annotations `.json`","metadata":{}},{"cell_type":"code","source":"out_json_data = {'images': im_list, 'annotations': an_list, 'categories': cat_list}\nwith open(coco_json_pth, 'w') as json_file:\n    json.dump(out_json_data, json_file, indent=4)\n    \nfor key, value in out_json_data.items():\n    print(key, value[:5])","metadata":{"execution":{"iopub.status.busy":"2023-12-30T12:08:41.207660Z","iopub.execute_input":"2023-12-30T12:08:41.207959Z","iopub.status.idle":"2023-12-30T12:08:48.970573Z","shell.execute_reply.started":"2023-12-30T12:08:41.207914Z","shell.execute_reply":"2023-12-30T12:08:48.969284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Modifichiamo i file train.txt, val.txt, test.txt per fare in modo che contengano tutti i crop associati alle singole immagini.  \nAl momento nel file .txt è contenuto il percorso all'immagine a dimensione originale ma non al crop.  \nVengono creati i nuovi file train2, val2, test2 da sostituire ai file originali","metadata":{}},{"cell_type":"code","source":"#os.remove('/kaggle/working/YOLO_cfg/val2.txt')\n#os.remove('/kaggle/working/YOLO_cfg/train2.txt')\n#os.remove('/kaggle/working/YOLO_cfg/test2.txt')\n\nfor txt in ['train.txt', 'val.txt', 'test.txt']:\n    filepath = '/kaggle/working/YOLO_cfg/' + txt\n    with open(filepath, 'r') as file:\n        lines = [line.strip() for line in file.readlines()]\n\n    line = []\n    for elem in lines:\n        line.append(elem.split('/')[-1].split('.')[0])\n\n    newfilepath = '/kaggle/working/YOLO_cfg/' + txt.split('.')[0] + '2.txt'\n    with open(newfilepath, 'a') as file:\n        for img in os.listdir('/kaggle/working/images/'):\n            if (txt != 'test.txt'):\n                if ((img.split('img_')[-1].split('_')[0]) in line): #sto prendendo solamente il numero associato all'immagine in 'images'\n                    file.write(str(future_ds_img_fldr) + '/' + img + '\\n')\n            else:\n                if ((img.split('img_')[-1].split('.')[0]) in line): #sto prendendo solamente il numero associato all'immagine in 'images'\n                    file.write(str(future_ds_img_fldr) + '/' + img + '\\n')\n","metadata":{"execution":{"iopub.status.busy":"2023-12-30T12:08:48.972046Z","iopub.execute_input":"2023-12-30T12:08:48.972629Z","iopub.status.idle":"2023-12-30T12:08:49.268842Z","shell.execute_reply.started":"2023-12-30T12:08:48.972599Z","shell.execute_reply":"2023-12-30T12:08:49.267480Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Eliminiamo i file train.txt, val.txt, test.txt e rinominiamo quelli creati al blocco di sopra per sostituirli.","metadata":{}},{"cell_type":"code","source":"os.remove('/kaggle/working/YOLO_cfg/train.txt')\nos.rename('/kaggle/working/YOLO_cfg/train2.txt', '/kaggle/working/YOLO_cfg/train.txt')\n\nos.remove('/kaggle/working/YOLO_cfg/val.txt')\nos.rename('/kaggle/working/YOLO_cfg/val2.txt', '/kaggle/working/YOLO_cfg/val.txt')\n\nos.remove('/kaggle/working/YOLO_cfg/test.txt')\nos.rename('/kaggle/working/YOLO_cfg/test2.txt', '/kaggle/working/YOLO_cfg/test.txt')","metadata":{"execution":{"iopub.status.busy":"2023-12-30T12:08:49.270073Z","iopub.execute_input":"2023-12-30T12:08:49.270584Z","iopub.status.idle":"2023-12-30T12:08:49.275483Z","shell.execute_reply.started":"2023-12-30T12:08:49.270555Z","shell.execute_reply":"2023-12-30T12:08:49.274379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Eseguo la conversione delle immagini di test (non labellate) da .tif a .jpg per averle nel dataset di output","metadata":{}},{"cell_type":"code","source":"if not os.path.exists('/kaggle/working/TestImages'):\n    os.mkdir('/kaggle/working/TestImages')","metadata":{"execution":{"iopub.status.busy":"2023-12-30T12:08:49.276604Z","iopub.execute_input":"2023-12-30T12:08:49.276873Z","iopub.status.idle":"2023-12-30T12:08:49.285699Z","shell.execute_reply.started":"2023-12-30T12:08:49.276848Z","shell.execute_reply":"2023-12-30T12:08:49.284643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\nfor img_name in os.listdir('/kaggle/input/xview-dataset/val_images/val_images/'):\n    img_path = '/kaggle/input/xview-dataset/val_images/val_images/' + img_name\n    img_name = img_name.split('.')[0] + '.jpg'\n    output_path = '/kaggle/working/TestImages/' + img_name\n    convert_tif_to_jpg(img_path, output_path)","metadata":{"execution":{"iopub.status.busy":"2023-12-30T12:08:49.287202Z","iopub.execute_input":"2023-12-30T12:08:49.287925Z","iopub.status.idle":"2023-12-30T12:11:12.126548Z","shell.execute_reply.started":"2023-12-30T12:08:49.287885Z","shell.execute_reply":"2023-12-30T12:11:12.125212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.listdir('/kaggle/working/')","metadata":{"execution":{"iopub.status.busy":"2023-12-30T12:11:12.128149Z","iopub.execute_input":"2023-12-30T12:11:12.128620Z","iopub.status.idle":"2023-12-30T12:11:12.136822Z","shell.execute_reply.started":"2023-12-30T12:11:12.128568Z","shell.execute_reply":"2023-12-30T12:11:12.135797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Download dataset","metadata":{}},{"cell_type":"code","source":"zip_dir()","metadata":{"execution":{"iopub.status.busy":"2023-12-30T12:11:12.138429Z","iopub.execute_input":"2023-12-30T12:11:12.138840Z","iopub.status.idle":"2023-12-30T12:11:43.712750Z","shell.execute_reply.started":"2023-12-30T12:11:12.138804Z","shell.execute_reply":"2023-12-30T12:11:43.711738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}